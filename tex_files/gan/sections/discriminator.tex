\documentclass[../gan.tex]{subfiles}
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discriminator}
Discriminator is a classifier that lears to distinguishes between real and fake images. Real images come from our training set, and the fake images are the ones generated by the generator. In mathematical terms, the discriminator will model $P(fake | X_{features})$.

\section{Generator}
Generator is the core model that is used ultimately in the end to generate new images. The aim of the training process should be to generate as good a version of the generator as possible. The input to the generator is a noise vector (different vectors should generate different outputs) that passes through the neural network (CNN in case of images) and the output is an image.

The generator learns a probability distribution over the set of training images such that any sample of the input space is highly likely to generate features that are common to most of the training data (cats, and possibly less likely to generate those features that were rare in the dataset, say specific breeds that were less represented in the data). In case of different classes, these distributions will be different for each class depending on the data. Mathematically, this models $P(X_{features})$ (or $P(X|y)$).

\section{Binary Cross Entropy Loss}
Assuming $h(x, \theta)$ representing the model, binary cross entropy loss is defined as
\begin{align*}
    J = -\frac{1}{m} \sum_{i=1}^{m} [y_{i} log h(x_{i}, \theta) + (1 - y_{i})log(1 - h_{x_{i}, \theta})]
\end{align*}
where $m$ is the number of examples over which the loss is calculated, $x_{i}$ represent the input features, and $y_{i}$ represent the correct label of the example (real/fake).

\section{GAN Training}
Happens in an alternating fashion
\begin{itemize}
    \item First the generator weights are kept constant, and BCE loss is calculated using both real and fake examples to update the weights of the discriminator.
    \item Then, the discriminator weights are kept constant and fake examples are generated from the generator. Only these fake examples are used to calculate BCE loss and update the generator weights.
    \item Since the task of generation of data is harder than classification, the generator is trained for a couple of steps for every training step of the discriminator.
    \item Truncated normal distribution is used for sampling since during training, the model is likely to see noise vectors close to the mean more often than other areas. This will make it more likely to generate good quality images closer to the mean. Hence, when sampling, we limit the sampled values to lie a fixed distance away from the mean. This is a tradeoff between good quality results and variety in results.
\end{itemize}
Both generator and discriminator should be at a similar skill level.

\section{Mode Collapse}
Mode is an area in a probability distribution with high density.
Suppose we are building a GAN for handwritten digits generation. Lets assume that the distribution of these digits (in some low dimensional space) has 10 modes such that areas around each mode correspond to the same digit. Now, suppose we arrive at a case where the discriminator is able to classify 8 digits correctly as real and fake, but is not able to do so for 2 digits 1 and 7. Generator can see this and start to generate more and more 1 and 7 thinking its the discriminators weakness. Our generator has a mode collapse where it is now trying to model only 2 modes in the data.
Discriminator might get out of this local minima with time, but that can cause the generator to stop learning overall. Same collapse can also happen on some other digits as we train. This is a classic example of model collapse where our data distribution should ideally have 10 modes but the generator is working with a lesse number.

\subsection{Problems with Binary Cross Entropy Loss}
Discriminator is much easier to train than the generator (discriminator needs to output a single value vs generator needs to output multiple values with a large range). Hence, during training it is entirely possible that the discriminator gets really good at distinguishing real and fake images. When this happens, its output will be very close to 0 and 1 for fake and real images respectively. This creates flat regions in the cost function giving less and less feedback to the generator for effective learning. This is similar to the vanishing gradients problem.

\subsection{Earth Movers Distance}
This aims to solve the problem of vanishing gradient with BCE loss. The distance measures the amount of effort it would take to match two distributions (real and fake images). Assume we have two normal distribuitions with the same variance but different means. If these were piles of dirt, the amount of dirt needed to move will depend on the distribution. Earth movers distance also takes into account how far away the distributions are (since moving the dirt over larger distance would require more effort). This effort is real and the associated cost is not limited to 0 or 1.

\subsection{Wasserstein Loss}
Suppose we have a critic function (discriminator) that outputs a real value related to how good or bad is the classification. Then,
\begin{align*}
    \text{W-loss} &= E[c(x)] - E[c(g(z))]\\
    \text{Objective} &\rightarrow \min_{g}\max_{c} E[c(x)] - E[c(g(z))]
\end{align*}
where $x$ is the input for the real image and $z$ is the noise input to the generator. Maximizing over $c$ means that the discriminator is trying to push away the predictions for real and fake images as far away as possible so that it's performance improves. On the other hand, minimization over $g$, the generator means that the generator is trying to generate better fake images such that the predictions of the discriminator for both real and fake images are close to each other.

Now the outputs of the critic (discriminator) are not bounded to 0 and 1 but can take any real values (hence the distinction to call it critic rather than a discriminator). Now we are also not using any $log$ term since the output of critic is now real anyways.

\subsubsection{1-Lipschitz Continuous}
For the Wasserstein loss to work well, the norm of the gradient at any point should be at most 1. This ensures that the growth of the function at any point is at most linear and the training is stable due to this limit on the growth. There are two common ways to enforce this
\begin{itemize}
    \item Gradient Clipping: After calculation of the gradient, its values are clipped between -1 and 1 before using it for updating weights. This clipping can limit the critics ability to learn.
    \item Regularization/Gradient Penalty: We modify the cost function to have an additional term related to the norm of the gradient for a softer version of enforcing 1-Lipschitz continuity.
    \begin{align*}
        \text{W-loss} &= E[c(x)] - E[c(g(z))] + \lambda\frac{1}{n}\sum(\lvert\lvert c(\hat{x}) \rvert\rvert_{2} - 1)^{2}\\
        \hat{x} &= \epsilon x_{real} + (1-\epsilon) x_{fake}
    \end{align*}
    Since it is difficult to enforce the gradient penalty on all points in the loss plane, we will calculate the gradients on a weighted average of the real and fake images (denoted by $\hat{x}$ above). This intermediate image helps take both the real and fake images into account. The mean of all the gradients is forced to be close to 1 by this regularization term. \textbf{Note that when we are minimizing the loss, we will put a negative sign before the expectations, the gradient penalty will remain the same}.
\end{itemize}

\section{Condititonal and Controllable Generation}
\subsection{Conditional Generation}
To train a GAN for conditional generation, labelled dataset is needed for training. To do so, we pass an additional input to the generator that is a one hot encoded vector representing which class we want to generate the data from. We concatenate the noise vector and one hot vector and pass this as the input.
For the discriminator, we will pass the class information along with the input image. This way, the discriminator can provide the correct feedback to the generator. We encode the one hot information into the channels of the image. Thus, now there are number of classes additional channels such that one channels is entirely consisting of 1 while remaining are all zero. This makes the matrix pretty large and other methods of adding this information can be preferred.
\subsection{Controllable Generation}
Controllable generation allows control over what specific features we wish for in our output examples, whereas in conditional generation, we were controlling the specific class for which we wish to generate the output. Controllable generation will require manipulating the input noise vector in a meaningful way to only tweak the specific feature, while conditional generation required appending the label information along with the noise vector. We dont need a labelled training dataset here (which we required in conditional generation).
To control the outputs, we need to find directions in the noise space such that adding that to our image produces the desired changes. For instance, if we have noise values that generate the image of the same person with different hair colour, the difference of the two vectors will give the required direction that can be used to manipulate image of any other person. We can also do a linear interpolation of these two vectors to get gradual changes to the hair colour.

\subsubsection{Classifier Gradients}
We can use a classifier to get feedback on whether a generated image has the required features or not. Consider a pipeline where we use a noise vector, pass it through a trained generator (forzen weights) and then pass this output to a trained classifier (say of sunglasses in image, frozen weights) and then finally get the classification output. We can use this feedback to directly update the noise vector such that it finally corresponds to the feature we want.
\end{document}
