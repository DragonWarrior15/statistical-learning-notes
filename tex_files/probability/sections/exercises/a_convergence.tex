\documentclass[../../probability-notes.tex]{subfile}
\begin{document}
        \begin{enumerate}
            \item No, since $X_{i}$ is also uniform in $[-1,1]$
            \item Yes, $E[Y_{i}] = 0$ by symmetry. For $\epsilon > 0$,
            \begin{align*}
                \lim_{i \to \inf}(P\vert Y_{i} - \mu_{i} \vert > \epsilon) &= \lim_{i \to \inf} P(\vert \frac{X_{i}}{i} - 0 \vert > \epsilon)\\
                &= \lim_{i \to \inf} P(\frac{X_{i}}{i} > \epsilon \text{ and } \frac{X_{i}}{i} < -\epsilon)\\
                &= \lim_{i \to \inf} [P(X_{i} > i\epsilon) + P(X_{i} < -i\epsilon)] = 0
            \end{align*}
            \item Yes, $E[Y_{i}] = 0$ by symmetry. For $\epsilon > 0$,
            \begin{align*}
                \lim_{i \to \inf}P(\vert Z_{i} - 0 \vert > \epsilon) &= \lim_{i \to \inf}P((X_{i})^{i} > \epsilon \text{ or } (X_{i})^{i} < -\epsilon)\\
                &= \lim_{i \to \inf} [\frac{1}{2}(1 - \epsilon^{1/i}) + \frac{1}{2}(1 - \epsilon^{1/i})]\\
                &= \lim_{i \to \inf}(1 - \epsilon^{1/i}) = 0
            \end{align*}
        \end{enumerate}
\end{document}