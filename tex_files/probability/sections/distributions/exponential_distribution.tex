\documentclass[../../probability-notes.tex]{subfiles}
\begin{document}
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Exponential Distribution}
    Exponential distribution is characterized by the parameter $\lambda$ and has the following probability distribution
    \begin{align*}
        f_{X}(x) = \begin{cases} 0 &\mbox{if $x < 0$}\\
                                \lambda e^{-\lambda x} &\mbox{otherwise} \end{cases}
    \end{align*}

    Exponential distribution is used to represent the interarrival time probability distribution in the context of Poisson Process. The cumulative distribution is given by
    \begin{alignat*}{2}
        F_{X}(x) &= \begin{cases} 0 &\mbox{if $x < 0$}\\
                                1 - e^{-\lambda x} &\mbox{otherwise} \end{cases}\\
        P(X > x) &= \int_{x}^{\infty} \lambda e^{-\lambda x} dx\\
        &= e^{-\lambda x}
    \end{alignat*}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Mean and Variance}
    The mean of the distribution is given by
    \begin{align*}
        E[x] &= \int_{0}^{\infty} \lambda x e^{-\lambda x} dx\\
        &= [-x e^{-\lambda x}]_{0}^{\infty} + \int_{0}^{\infty} e^{-\lambda x} dx = \frac{1}{\lambda}\\
        \Aboxed{E[X] &= \frac{1}{\lambda}}
    \end{align*}
    where we used integration by parts, $\int uv' = uv - \int u'v$ and substituted $u = x$ and $v = -e^{-\lambda x}/\lambda$.\newline

    For variance, we first calculate the value of $E[x^{2}]$
    \begin{align*}
        E[x^{2}] &= \int_{0}^{\infty} \lambda x^{2} e^{-\lambda x} dx\\
        &= [-x^{2} e^{-\lambda x}]_{0}^{\infty} + \int_{0}^{\infty} 2x e^{-\lambda x} dx\\
        &= [\frac{-2x e^{-\lambda x}}{\lambda}]_{0}^{\infty} - [\frac{2e^{-\lambda x}}{\lambda^{2}}]_{0}^{\infty}\\
        &= \frac{2}{\lambda^{2}}\\
        Var(X) &= E[X^{2}] - E[X]^{2}\\
        \Aboxed{Var(X) &= \frac{1}{\lambda^{2}}}
    \end{align*}
    The above property can be generalized for the $n$th power as well
    \begin{align*}
        E[X^{n}] = \frac{n!}{\lambda^{n}}
    \end{align*}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Moment Generating Function}
    The moment generating function of an exponential distribution can be derived as follows
    \begin{align*}
        E[e^{tX}] &= \int_{-\infty}^{\infty} e^{tx} \lambda e^{-\lambda x} dx = \frac{\lambda}{\lambda - t} \int_{-\infty}^{\infty} (\lambda - t) e^{-(\lambda - t)x} dx\\
        &= \frac{\lambda}{\lambda - t}
    \end{align*}
    since quantity under the integral is an exponential distribution with the parameter $\lambda - t$.

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Memoryless Property}
    A fundamental mathematical property of the exponential distribution is the memoryless property. In summary, this means that whatever has transpired till now will not affect the future distribution. Mathematically $P(T > t+s)$ is independent of t
    \begin{align*}
        P(T > t+s | T>t) &= \frac{P(T> t+s \text{ and }T > t)}{P(T > t)}\\
        &= \frac{P(T > t + s)}{P(T > t)}\\
        &= \frac{e^{-\lambda(t+s)}}{e^{-\lambda t}}\\
        &= e^{-\lambda s}\\
        \Aboxed{P(T > t+s | T>t) &= P(T > s)}
    \end{align*}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Minimum of Poisson Variables}
    If $X_{1}, \ldots X_{n}$ are $n$ independent Poisson distributed random variables with $X_{i} \sim Poisson(\lambda_{i})$, then the distribution of the minima is also Poisson.
    \begin{align*}
        P(min(X_{1}, \ldots, X_{n}) > x) &= P(X_{1} > x, \ldots, X_{n} > x)\\
        &= P(X_{1} > x) P(X_{2} > x) \ldots P(X_{n} > x) \; \text{by independence}\\
        &= \prod_{i=1}^{n} e^{-\lambda_{i} x}\\
        &= \exp(-\sum_{i=1}^{n} \lambda_{i} x)\\
        \implies min(X_{1}, \ldots, X_{n}) &\sim Poisson(\lambda_{1} + \cdots + \lambda_{n})
    \end{align*}
\end{document}
