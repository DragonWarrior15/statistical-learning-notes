\documentclass[../statistical_learning_notes.tex]{subfiles}
\begin{document}
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    % {\let\clearpage\relax \chapter{Classification}}
    \chapter{Classification}
    For more than two classes, it is hard to maintain the ordering between them using linear regression. For two classes however, linear regression can be used to prepare an ordering of the data (although difficult to interpret as probability themselves).\newline 
    \textbf{Classification using linear regression to predict binary reponse will be same as Linear Discriminant Analysis (LDA).}\newline

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Logistic Regression}
    Modelling binary response with linear regression might produce values outside the range $[0,1]$ ( and possibly negative as well). Hence we use a logistic function to compress the outputs to $[0,1]$ range.
    
    \begin{align*}
        p(Y=1|X) = \frac{1}{1+e^{-(\beta_{0}+\beta_{1}X)}}\\
        odds = \frac{p(Y=1|X)}{1-p(Y=1|X)} = e^{\beta_{0} + \beta_{1}X}
    \end{align*}
    \begin{itemize}
        \item The solution to this model is obtained via \textbf{Maximum Likelihood Estimation}.
        \item Odds are also used to interpret probability. A low value of odds (close to $0$) indicates a low probability while a high value (close to $\inf$) indicates a high probability.
        \item One unit change in $X$ will cause $\beta_{1}$ change in the $log\;odds$.
    \end{itemize}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Loss Function}\label{sec:classification_loss_fn}
    \textbf{Maximum Likelihood} is used to determine the coefficients. Basic intuition is to choose such a pair of $\beta's$ that will make the predicted probability as close to the correct binary response ($0$ or $1$) as possible.

    \begin{align*}
        \text{Denoting} \quad p(x_{i}) &= P(Y = 1 | X = x_{i}) = 1/(1 + exp(-\beta^{T}x_{i}))\\
        \text{likelihood function} &= l(\beta_{0},\beta_{1}) = \prod_{i:y_{i}=1} p(x_{i}) \prod_{i^{'}:y_{i^{'}}=0}(1-p(x_{i^{'}}))\\
        \text{Taking logarithm, } logloss &= \sum_{i:y_{i}=1} \log p(x_{i}) + \sum_{i^{'}:y_{i^{'}}=0}\log (1-p(x_{i^{'}}))\\
        &= \sum_{i=1}^{n} y\log p(x_{i}) + (1-y)\log (1+p(x_{i})) \tag*{since $y = 0$ or $1$}\\
        &= \sum_{i=1}^{n} y\beta^{T}x_{i} - log(1 + exp(\beta^{T}x_{i}))
    \end{align*}
    All the formulae listed here and above extend for the case of multiple variables, wherein we simply replace the sum $\beta_{0} + \beta_{1}X$ with $\beta_{0} + \beta_{1}X_{1} + \cdots + \beta_{p}X_{p}$.\newline

    For the below derivations, refer to section \ref{sec:appendix_classification_loss_fn} for complete matrix calculus
    To solve for the $\beta$s, we consider the derivate of the \emph{log likelihood}
    \begin{align*}
        \frac{\partial l}{\partial \beta} = \sum_{i=1}^{n} x_{i}(y_{i} - p_{i}) = 0
    \end{align*}
    which are $p-1$ non linear equations. We use the Newton-Raphson method and Hessian matrix for solving them
    \begin{align*}
        \frac{\partial^{2}l}{\partial \beta \partial \beta^{T}} &= -\sum_{i=1}^{n} x_{i}x_{i}^{T}p(x_{i})(1 - p(x_{i}))\\
        \beta^{new} &= \beta^{old} - \bigg( \frac{\partial^{2}l}{\partial \beta \partial \beta^{T}} \bigg)^{-1} \frac{\partial l}{\partial \beta}
    \end{align*}

    Converting the above equations to function form for ease of obtaining solution
    \begin{align*}
        \frac{\partial l}{\partial \beta} &= X^{T}(y - \mathbf{p})\\
        \frac{\partial^{2}l}{\partial \beta \partial \beta^{T}} &= -X^{T}WX\\
        \text{where} \quad W &= diag([p(x_{1})(1-p(x_{1})), \ldots, p(x_{n})(1-p(x_{n}))])
    \end{align*}

    and the Newton-Raphson update becomes
    \begin{align*}
        \beta^{new} &= \beta^{old} + (X^{T}WX)^{-1} X^{T}(y - \mathbf{p})\\
        &= (X^{T}WX)^{-1} X^{T}W(X\beta^{old} + W^{-1}(y - \mathbf{p}))\\
        &= (X^{T}WX)^{-1} X^{T}Wz
    \end{align*}
    where $z$ is called the adjusted response (target in regression). The equation is same as equation \ref{eq:linear_reg_solution} with an added weight term of $W$. Hence, this equation solves the weighted least squares problem
    \begin{align*}
        \beta^{new} = \argmin_{\beta} (z - X\beta)^{T}W(z - X\beta)
    \end{align*}
    and is known as \emph{iteratively reweighted least squares} (IRLS). The equation converges since \emph{log likelihood} is concave. In case of non convergence/huge jumps, reducing the step size helps.\newline

    Further, the above formulation allows us to get the distribution of $\beta$
    \begin{align*}
        \hat{\beta} \sim \mathcal{N}(\beta, (X^{T}WX)^{-1})
    \end{align*}

    Wald test, rao score test\newline

    In case of multiple classes, $y$ becomes a matrix of shape $n \times K$ and $W$ is non-diagonal, but the solution to IRLS is not simple. Methods like co-ordinate wise gradient descent works better.\newline


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Multiple Classes}
    Note that the log of odds formula above is the ratio of probability of $Y=1$ to probability of $Y=0$. Here, $Y=0$ can be seen as a reference class. Similarly, in the case of $K$ classes, we will have $K-1$ classifiers, each classifying with respect to the last class (since the decision boundary has to be between two classes) and will take the form
    \begin{align*}
        log \big( \frac{P(Y=1|X=x)}{P(Y=K|X=x)} \big) &= \beta_{1,0} + \beta_{1}^{T}x\\
        log \big( \frac{P(Y=2|X=x)}{P(Y=K|X=x)} \big) &= \beta_{2,0} + \beta_{2}^{T}x\\
        \vdots\\
        log \big( \frac{P(Y=K-1|X=x)}{P(Y=K|X=x)} \big) &= \beta_{K-1,0} + \beta_{K-1}^{T}x\\
        \text{and} \quad \sum_{k=1}^{K} P(Y=k|X=x) &= 1\\
        \text{Giving} \quad P(Y=k|X=x) &= \frac{exp(\beta_{k,0} + \beta_{k}^{T}x)}{1 + \sum_{j=1}^{K-1} exp(\beta_{j,0} + \beta_{j}^{T}x)} \quad \text{for $j<K$}\\
        P(Y=K|X=x) &= \frac{1}{1 + \sum_{j=1}^{K-1} exp(\beta_{j,0} + \beta_{j}^{T}x)}\\
        \text{Parameter Set} \quad \theta &= \{ \beta_{1,0}, \beta_{1}, \ldots, \beta_{K-1,0}, \beta_{K-1} \}
    \end{align*}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Linear Discriminant Analysis (LDA)}
    Why use LDA ?
    \begin{itemize}
        \item When the \textbf{classes are well separated}, the parameter estimates for the \textbf{logistic regression} model are surprisingly \textbf{unstable}. \textbf{LDA} does not suffer from this problem and is relatively \textbf{stable}.
        \item if \textbf{$n$ is small} and the distribution of \textbf{$X$ is approximately normal} in each of the classes, \textbf{LDA} is again \textbf{more stable} than logistic regression.
        \item LDA is popular when we have \textbf{more than two classes}.
    \end{itemize}

    LDA first models the distribution of $X$ in each class, and then uses Bayes' rule to flip this and get $p(Y|X)$. When these distributions of $X$ are normal, the model is very similar in form to logistic regression.

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Model Derivation}
    Let the total number of classes be $K$ and the prior probability that a randomly chosen observation comes from the $k^{th}$ class be $\pi_{k} = P(Y=k)$. Also, let $f_{k}(x) = P(X=x|Y=k)$ denote the probability distribution function of $X$ for the data points belonging to the class $k$. By Bayes' Rule
    \begin{align*}
        \pi_{k} &= \frac{\text{Observations in class k}}{\text{Total observations}}\\
        p(Y=k|X=x) &= \frac{P(Y=k)P(X=x|Y=k)}{P(X=x)}\\
                &= \frac{P(Y=k)P(X=x|Y=k)}{\sum_{l=1}^{K} P(Y=l)P(X=x|Y=l)}\\
                &=  \frac{\pi_{k}f_{k}(x)}{\sum_{l=1}^{K}\pi_{l}f_{l}(x)}
    \end{align*}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Gaussian Model with one Predictor}
    We assume the predictor to have a Gaussian distribution. For simplicity, also assume that the variances of $X$ for all the $K$ classes are also the same (fundamental assumption for linearity of decision boundary). Then,
    \begin{align*}
        f_{k}(x) &= \frac{1}{\sqrt{2\pi}\sigma}e^{\frac{(x-\mu_{k})^{2}}{2\sigma^{2}}}\\
        p_{k}(x) &= \frac{\pi_{k}\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{(x-\mu_{k})^{2}}{2\sigma^{2}}}}{\sum_{l=1}^{K}\pi_{l}\frac{1}{\sqrt{2\pi}\sigma}e^{\frac{(x-\mu_{l})^{2}}{2\sigma^{2}}}}
    \end{align*}
    
    For any given $x$, we notice that all $f_{k}(x)$'s have the same denominator. To assign a class, we just need to find the maximum value. Taking $\log$, removing the denominator and removing the parts corresponding to $x$ from numerator (since they are same across all classses),
    \begin{align*}
        \log{p_{k}(x)} \propto \log{\pi_{k}} + \frac{\mu_{k}^{2}}{2\sigma^{2}} - \frac{x\mu_{k}}{\sigma^{2}}
    \end{align*}

    In the case of two classes, the decision boundary can be found by equating the two $\log probabilities$ (assume the priors to be same for simplicity)
    \begin{align*}
        x\frac{\mu_{1}}{\sigma^{2}} - \frac{\mu_{k}^{2}}{2\sigma^{2}} &= x\frac{\mu_{2}}{\sigma^{2}} - \frac{\mu_{2}^{2}}{2\sigma^{2}} \\
        \text{or, } x &= \frac{\mu_{1} + \mu_{2}}{2} 
    \end{align*}

    $\mu_{k}$ and $\sigma^{2}$ need to be estimated from the data, which can be done through the following formulae ($n$ is total training examples and $n_{k}$ is total training examples from class $k$)
    \begin{align*}
        \hat{\mu_{k}} &= \frac{1}{n_{k}} \sum_{i:y_{i}=k}x_{i}\\
        \hat{\sigma^{2}} &= \frac{1}{N - K}\sum_{k=1}^{K}\sum_{i:y_{i}=k}(x-\hat{\mu_{k}})^{2}
    \end{align*}

    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Multivariate Gaussian}
    A Multivariate Gaussian is an extension of the 1-D gaussian to multiple dimensions. Here, we assume that each of the individual dimensions is itself a Gaussian, with the different dimensions having correlation with each other, which are all specified in the correlation matrix.
    \begin{align*}
        X &\sim \mathcal{N}(\mu, \Sigma) \\
        f(x) &= \frac{1}{(2\pi)^{p/2}\mid \Sigma \mid^{1/2}} \exp(-\frac{1}{2}(x-\mu)^{T}\Sigma^{-1}(x-\mu))
    \end{align*}

    Here, $\mu$ is the mean vector $\Sigma$ is the covariance matrix (symmetric). \newline 
    Assume $\mu_{k}$ represents the mean vector for individual classes and we have a common covariance matrix across all classes. Plugging this into the LDA equation and removing the common part across all classes, the discriminant becomes
    \begin{align*}
        \log{p_{k}(x)} \propto \log{\pi_{k}} + x^{T}\Sigma^{-1}\mu_{k} - \frac{1}{2}\mu_{k}^{T}\Sigma^{-1}\mu_{k}    
    \end{align*}

    To calculate the decision boundary, we simply do a pairwise equality between the discriminants of the individual classes and get the pairwise decision boundaries which are all linear.

    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Quadratic Discriminant Analysis (QDA)}
    The assumption of same covariance matrix $\Sigma$ across all classes is fundamental to LDA in order to create the linear decision boundaries. \newline
    However, in QDA, we relax this condition to allow class specific covariance matrix $\Sigma_{k}$. Thus, for the $k^{th}$ class, $X$ comes from $X \sim \mathcal{N}(\mu_{k}, \Sigma_{k}$. \newline
    Plugging this into the classification rule to get the discriminants (removing denominators as they are common for all classes)
    \begin{align*}
        \delta_{k}(x) &= \log{\pi_{k}} -\frac{1}{2}\log{\mid\Sigma \mid} - \frac{1}{2}(x-\mu_{k})^{T}\Sigma_{k}^{-1}(x-\mu_{k}) \\
        \text{Note that, } x^{T}\Sigma_{k}^{-1}\mu_{k} &= \mu_{k}^{T}\Sigma_{k}^{-1}x \text{  since $\Sigma$ is symmetric and $x^{T}\Sigma_{k}^{-1}\mu_{k}$ is scalar} \\
        \delta_{k}(x) &= \log{\pi_{k}} -\frac{1}{2}\log{\mid\Sigma \mid} - \frac{1}{2}x^{T}\Sigma_{k}^{-1}x + x^{T}\Sigma_{k}^{-1}\mu_{k} -\frac{1}{2}\mu_{k}^{T}\Sigma_{k}^{-1}\mu_{k}
    \end{align*}

    Notice the term $x^{T}\Sigma_{k}^{-1}x$ that gives the classifier it's quadratic form. \newline
    However, since we are calculating individual covariance matrices for all the classes, we need to calculate more parameters than before which requires more data. \newline
    The following points about QDA vs LDA must be noted
    \begin{itemize}
        \item QDA requires evaluation of substantially more parameters than LDA which subsequently means that more training data points must be available.
        \item QDA will be superior if the decision boundaries are not linear, i.e., LDA's assumption of equal variances for all classes will not hold true which will cause LDA to have a higher bias.
        \item QDA is more flexible than LDA which can reduce bias. However, bias-variance tradeoff implies that variance can be relatively higher for QDA if training examples are not sufficient.
    \end{itemize}

    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Comparison of Classifiers}
    Logistic Regression and LDA are similar in the sense that they produce linear decision boundaries.
    \begin{itemize}
        \item Logistic Regression estimates coefficients using Maximum Likelihood Estimate
        \item LDA estimates parameters using the sample mean and variance
    \end{itemize}
    For both the models, $\log {odds}$ takes a linear form. LDA adds a strong assumption of normal distribution of the predictor variables.\newline
    
    Comparison of models
    \begin{itemize}
        \item Logistic Regression is the simplest classifier one can build. It assumes linearly separated decision boundaries. It is usually used as a binary classifier. The decision boundary can be made non linear by adding transformed version of the predictors like second powers, interaction terms etc.
        \item LDA is also a linear classifier, but works under the assumptions that the decision boundaries are linear and all the classes share the same covariance matrix. It works well with multiple classes. The performance can be quite bad if the underlying variables are not normally distributed.
        \item QDA is a natural extension of LDA that relaxes the assumption of shared covariance matrix and allows each class to have a separate covariance matrix. This causes QDA to work well when decision boundaries have non linearity
        \item KNN is a non parametric model that is the most flexible. However, we can get no indication of which predictor is important, and the model can suffer from high variance.
    \end{itemize}


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Classfication Metrics}
    Several classification metrics are available for binary classifiers which are used based on the problem setting.

    \subsection{Confusion Matrix}
    This matrix tabulates the number of cases we are classifying and misclassifying.
    \begin{table}[h]
    \centering
    \begin{tabular}{c|c|c}
        Confusion Matrix & \textbf{Actual Positive} & \textbf{Actual Negative}\\ \hline
        \textbf{Predicted Positive} & True Positive & False Positive\\ \hline
        \textbf{Predicted Negative} & False Negative & True Negative\\
    \end{tabular}
    % \caption{Confusion Matrix}
    \end{table}

    Based on the above table, we define the following terms
    \begin{itemize}
        \item Accuracy $= \frac{TP + TN}{P+N}$
        \item Sensitivity or True Positive Rate (TPR) or Recall $= \frac{TP}{P} = \frac{TP}{TP+FN}$
        \item Specificity or True Negative Rate (TNR) $= \frac{TN}{N} = \frac{TN}{FP+TN}$
        \item Precision or Positive Predicted Value (PPV) $= \frac{TP}{FP+TP}$
        \item False Positive Rate $= \frac{FP}{N} = \frac{FP}{FP+TN}$
        \item $F_{1}$ Score $= \frac{2 * precision * recall}{precision + recall}$
    \end{itemize}

    \subsection{Receiver Operating Characteristics (ROC Curve)}
    ROC curve is plot between \textbf{True Positive Rate} and \textbf{False Positive Rate}, or equivalently, between \textbf{sensitivity/recall} and \textbf{$1 - $ specificity}. The area under the plotted curve is know as AUC score. \newline
    The curve is plot by repeatedly constructing the confusion matrix at different probability thresholds (i.e. changing the decision boundary to see how the confusion matrix changes).\newline
    ROC Curve is agnostic of the class balancing in the data set, and is thus used frequently in case of class imbalance to judge a classifier. A random classifier will have AUC of $0.5$ as at any threshold, the number of correctly and incorrectly classified points will roughly be the same. A perfect classifier will be able to segregate the population perfectly and will have the value of AUC as $1.0$.


\end{document}