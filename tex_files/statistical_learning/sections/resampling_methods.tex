\documentclass[11pt, a4paper]{article}

\usepackage{amsmath}
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{amsfonts}
\usepackage{mathtools}

% \usepackage{tikz}
% \usetikzlibrary{automata, positioning}

% \usepackage{pgfplots}
% \pgfplotsset{width=5cm,compat=1.9}
\setlength{\parindent}{0em}

\begin{document}
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \section{Resampling Methods}
    Sampling methods are a class of methods that serve a twofold purpose
    \begin{itemize}
        \item Provide a subset of data to be used for evaluating the test error rate
        \item Use different samples of data to assess the variability in the model parameters to choose the level of flexibility
    \end{itemize}


    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Cross Validation}
    Validation set approach forms the bedrock for cross validation. We randomly split our training data into two sets, a training set and a validation set. We fit our models on the training set, and the validation set will serve as the unseen data. We can evaluate different models on the validation test to judge which of them performs the best.\newline
    A small problem with this approach is that the validation error will depend on the split of the data, i.e., we can expect slighlty different validation errors based on which subset of data we train. Hence, it is better to do this sampling multiple times in order to confidently select models and report test errors. \newline
    Furthermore, by preparing a validation set, we are reducing the size of our training set. Larger training data will usually result in better models. Hence, we might be overestimating the test errors in this case. A simple way to avoid this problem is to choose small sizes of the validation set and do the tests multiple times.

    \subsubsection{Leave One Out CV}
    An extension of the validation approach, here we train the data on all but on example. This way, if the data has $n$ examples, we build $n$ models (each trained on $n-1$ examples) and the error is
    \begin{align*}
        \text{test error } = \frac{1}{n}\sum_{i=1}^{n} error_{i}\\
    \end{align*}
    where $error_{i}$ is the error on $i^{th}$ observation from the model trained on remaining $n-1$ observations\newline

    Computing this can be extremely expensive when $n$ is large. For linear regression, there exists a trick by which the time taken to get $test\;error$ is exactly the same as the time to fit a single model on entire data set !\newline
    \begin{align*}
        \hat{\beta} &= (X^{T}X)^{-1}X^{T}Y \\
        \text{Hat matrix  } H &= X(X^{T}X)^{-1}X^{T}
    \end{align*}
    
    Let $X_{i}$ denote the matrix $X$ but with the $i^{th}$ row removed, and similarly $Y_{i}$. Let $x_{i}^{T}$ denote the $i^{th}$ row of $X$ and $h_{i}$ be the diagonal entry of $H$. Then we have the following
    \begin{align*}
        X_{i}^{T}X_{i} &= X^{T}X - x_{i}x_{i}^{T}\\
        X_{i}^{T}Y &= X^{T}Y - x_{i}y_{i}\\
        h_{i} &= x_{i}^{T}(X^{T}X)^{-1}x \\
        \hat{\beta_{i}} &= (X_{i}^{T}X_{i})^{-1}X_{i}^{T}Y_{i} \\
        e_{i} &= y_{i} - x_{i}^{T}\hat{\beta_{i}}
    \end{align*}

    Also, we have the Shermanâ€“Morrison formula for calculating the inverse of a perturbated matrix using the original matrix. Let $A$ be the original invertible square matrix and $u,v$ be column vectors. Then,
    \begin{align*}
        (A + uv^{T})^{-1} = A^{-1} - \frac{A^{-1}uv^{T}A^{-1}}{1+v^{T}A^{-1}u}
    \end{align*}
    The formula can be verified by evaluating $LHS * RHS = RHS * LHS = I$. \newline

    Substituiting $A = X^{T}X$ and $-u = v = x_{i}$,
    \begin{align*}
        (X^{T}X - x_{i}x_{i}^{T})^{-1} &= (X^{T}X)^{-1} + \frac{(X^{T}X)^{-1}x_{i}x_{i}^{T}(X^{T}X)^{-1}}{1-x_{i}^{T}(X^{T}X)^{-1}x_{i}}\\
        (X_{i}^{T}X_{i})^{-1} &= (X^{T}X)^{-1} + \frac{(X^{T}X)^{-1}x_{i}x_{i}^{T}(X^{T}X)^{-1}}{1-x_{i}^{T}(X^{T}X)^{-1}x_{i}}\\
        \hat{\beta_{i}}(X_{i}^{T}Y_{i})^{-1} &= (X^{T}X)^{-1} + \frac{(X^{T}X)^{-1}x_{i}x_{i}^{T}(X^{T}X)^{-1}}{1-x_{i}^{T}(X^{T}X)^{-1}x_{i}}\\
        \hat{\beta_{i}} &= [(X^{T}X)^{-1} + \frac{(X^{T}X)^{-1}x_{i}x_{i}^{T}(X^{T}X)^{-1}}{1-x_{i}^{T}(X^{T}X)^{-1}x_{i}}](X_{i}^{T}Y_{i})\\
        \hat{\beta_{i}} &= [(X^{T}X)^{-1} + \frac{(X^{T}X)^{-1}x_{i}x_{i}^{T}(X^{T}X)^{-1}}{1-h_{i}}](X^{T}Y - x_{i}y_{i})\\
        \hat{\beta_{i}} &= \hat{\beta} - [\frac{(X^{T}X)^{-1}x_{i}}{1-h_{i}}](y_{i}(1-h_{i})-x_{i}^{T}\hat{\beta_{i}+h_{i}y_{i}})\\
        &= \hat{\beta} - [\frac{(X^{T}X)^{-1}x_{i}(y_{i}-x_{i}^{T}\hat{\beta})}{1-h_{i}}]\\
        \text{Subsequently, } e_{i} &= y_{i} - x_{i}^{T}\hat{\beta_{i}}\\
                                &= y_{i} - x_{i}^{T}(\hat{\beta} - [\frac{(X^{T}X)^{-1}x_{i}(y_{i}-x_{i}^{T}\hat{\beta})}{1-h_{i}}])\\
                                &= (y_{i}-x_{i}^{T}\hat{\beta}) + \frac{h_{i}(y_{i}-x_{i}^{T}\hat{\beta})}{1-h_{i}}\\
            \text{or, } e_{i} &= \frac{y_{i}-x_{i}^{T}\hat{\beta}}{1-h_{i}}\\
                             &= \frac{y_{i}-\hat{y_{i}}}{1-h_{i}}
    \end{align*}
    Applying this formula for all the errors across the $n$ models,
    \begin{align*}
        \text{test error } &= \frac{1}{n}\sum_{i=1}^{n} error_{i}\\
                        &= \frac{1}{n}\sum_{i=1}^{n} (\frac{y_{i}-\hat{y_{i}}}{1-h_{i}})^{2}
    \end{align*}
    which can be computed by simply building a single model on all the $n$ data points.
\end{document}